"""
config.py
---------
Central configuration for experiments: variable definitions, hyperparameter 
search spaces, dropout types, divergence methods, and global settings.

To use a different target/input variables, modify VARIABLE_CONFIG below.
"""
import random
import numpy as np
import torch

# ─────────────────────────────────────────────────────────────────────────────
# Reproducibility
# ─────────────────────────────────────────────────────────────────────────────

def set_seeds(seed: int = 42):
    """Set random seeds for reproducibility across all libraries."""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


# ─────────────────────────────────────────────────────────────────────────────
# Device
# ─────────────────────────────────────────────────────────────────────────────

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"


# ─────────────────────────────────────────────────────────────────────────────
# Date Range (full data in CSV)
# ─────────────────────────────────────────────────────────────────────────────

# Full data range (local CSV contains 2010-2025)
DATA_START = "2010-01-01"
DATA_END = "2025-01-01"

# Sample period filter (applied after loading data)
# Options: 'full', 'pre_covid', 'post_covid', 'recent', or custom tuple
SAMPLE_PERIOD = 'full'  # Default: 2010-2025

# Sample period definitions
SAMPLE_PERIODS = {
    'full': ('2010-01-01', '2025-01-01'),       # All data (15 years)
    'recent': ('2019-01-01', '2025-01-01'),     # Recent 6 years
    '2015_2025': ('2015-01-01', '2025-01-01'),  # Last 10 years
    '2010_2019': ('2010-01-01', '2019-01-01'),  # Pre-recent period
    'pre_covid': ('2010-01-01', '2020-02-01'),  # Before COVID crash
    'post_covid': ('2020-07-01', '2025-01-01'), # After COVID recovery
    'covid_only': ('2020-01-01', '2021-01-01'), # COVID period only
}

# Legacy compatibility
START_DATE = "2010-01-01"
END_DATE = "2026-01-01"


# ─────────────────────────────────────────────────────────────────────────────
# ⭐ EXPERIMENT PROFILES ⭐
# 6 experiments: gold_price × 3 periods + sp500_price × 3 periods
# Select with CLI: --config gold_price_p1
# ─────────────────────────────────────────────────────────────────────────────

CURRENT_EXPERIMENT = 'gold_price_2010_2025'  # Default experiment (full period)

# Period definitions with date-based naming
PERIODS = {
    '2010_2015': ('2010-01-01', '2015-01-01'),  # Subperiod 1: 2010-2014
    '2015_2020': ('2015-01-01', '2020-01-01'),  # Subperiod 2: 2015-2019
    '2020_2025': ('2020-01-01', '2026-01-01'),  # Subperiod 3: 2020-2025
    '2010_2025': ('2010-01-01', '2026-01-01'),  # Full period: 2010-2025
}

# Base experiment configs
# ─────────────────────────────────────────────────────────────────────────────
# STANDARDIZED FEATURE SET (Same for all experiments to ensure comparability)
# Macro: VIX (volatility), DXY (dollar), TNX (interest rates)
# Technical: MA_20 (trend, single MA to avoid multicollinearity)
# Note: Lag feature is added automatically based on target type
# ─────────────────────────────────────────────────────────────────────────────

# Standard macro features available in both gold_data.csv and sp500_enhanced_data.csv
_STANDARD_FEATURES_GOLD = ['vix', 'dxy', 'tnx', 'MA_20']  # lowercase for gold CSV
# Standard macro features available in gold_data.csv
_STANDARD_FEATURES_GOLD = ['vix', 'dxy', 'tnx', 'MA_20']

_GOLD_PRICE_BASE = {
    'target_ticker': 'GLD',
    'target_name': 'Gold (SPDR)',
    'data_file': 'gold_data.csv',
    'extra_feature_cols': _STANDARD_FEATURES_GOLD,
    'transformation': 'price',
    'transform_inputs': False,
    'target_col': 'price',  # For lag feature generation
}
_GOLD_BASE = _GOLD_PRICE_BASE  # Backward compatibility alias

_GOLD_RETURNS_BASE = {
    'target_ticker': 'GLD',
    'target_name': 'Gold Returns',
    'data_file': 'gold_data.csv',
    'extra_feature_cols': _STANDARD_FEATURES_GOLD,
    'transformation': 'log_returns',
    'transform_inputs': False,  # Don't transform inputs, they are levels
    'target_col': 'returns',  # For lag feature generation - USE RETURN LAG!
}



# Generate experiment configs for each period
EXPERIMENTS = {}

for period_name, (start, end) in PERIODS.items():
    # Gold Price experiments
    EXPERIMENTS[f'gold_price_{period_name}'] = {
        **_GOLD_PRICE_BASE,
        'target_name': f'Gold Price ({period_name.upper()})',
        'period': (start, end),
    }
    
    # Gold Returns experiments
    EXPERIMENTS[f'gold_returns_{period_name}'] = {
        **_GOLD_RETURNS_BASE,
        'target_name': f'Gold Returns ({period_name.upper()})',
        'period': (start, end),
    }
    


# NOTE: All experiments are now generated by the loop above with date-based naming.
# Legacy names (gold_price, gold_price_full, sp500_price_v2_*) are REMOVED.
# Use: gold_price_2010_2025, gold_price_2010_2015, sp500_price_2010_2025, etc.

# Get current experiment config
def get_experiment_config(name: str = None) -> dict:
    """Get experiment configuration by name."""
    name = name or CURRENT_EXPERIMENT
    return EXPERIMENTS.get(name, EXPERIMENTS['gold_price_2010_2025'])

# Legacy compatibility - populated from current experiment
_exp = get_experiment_config()
VARIABLE_CONFIG = {
    'target_ticker': _exp['target_ticker'],
    'target_name': _exp['target_name'],
    'input_tickers': _exp.get('input_tickers', {}),  # May not exist for local-file experiments
    'extra_feature_cols': _exp['extra_feature_cols'],
}

# Target variable settings
TARGET_COL = 'price'  # Column name for target (always 'price' after loading)
N_LAGS = 1            # Number of lag features to create


# ─────────────────────────────────────────────────────────────────────────────
# ⭐ PREPROCESSING CONFIGURATION ⭐
# ─────────────────────────────────────────────────────────────────────────────

PREPROCESSING_CONFIG = {
    'transformation': _exp.get('transformation', 'price'),
    'transform_inputs': _exp.get('transform_inputs', False),
    'run_diagnostics': True,
}


# ─────────────────────────────────────────────────────────────────────────────
# Training Settings
# ─────────────────────────────────────────────────────────────────────────────

SEARCH_EPOCHS = 20      # Epochs during hyperparameter search
RETRAIN_EPOCHS = 30     # Epochs for final retraining
LEARNING_RATE = 0.001
BATCH_SIZE = 16
GRADIENT_CLIP = 5.0


# ─────────────────────────────────────────────────────────────────────────────
# Dropout Types
# ─────────────────────────────────────────────────────────────────────────────

DROPOUT_TYPES = ['none', 'fixed', 'monte_carlo', 'dynamic', 'adaptive']


# ─────────────────────────────────────────────────────────────────────────────
# Divergence Methods
# ─────────────────────────────────────────────────────────────────────────────

DIVERGENCE_METHODS = [
    'js', 'kl', 'reverse_kl', 'hellinger', 'tv', 'pearson_chi_square',
    'wasserstein', 'bregman_euclidean', 'bregman_exponential',
    'bregman_log', 'renyi', 'jensen_renyi', 'bhattacharyya', 'tsallis'
]


# ─────────────────────────────────────────────────────────────────────────────
# Hyperparameter Search Space (for Optuna)
# ─────────────────────────────────────────────────────────────────────────────

HYPERPARAM_SPACE = {
    'num_layers': [2, 3, 4],
    'hidden_size': [128, 256, 512],
    'base_rate': (0.01, 0.50),      # Continuous range
    'alpha': (0.0, 10.0, 0.5),      # Min, max, step
}


# ─────────────────────────────────────────────────────────────────────────────
# Best Model Configuration (from previous experiments)
# ─────────────────────────────────────────────────────────────────────────────

BEST_MODEL_CONFIG = {
    'dropout_type': 'adaptive',
    'divergence_method': 'hellinger',
    'num_layers': 3,
    'hidden_size': 256,
    'base_rate': 0.35,
    'alpha': 6.0,
}


# ─────────────────────────────────────────────────────────────────────────────
# Output Paths
# ─────────────────────────────────────────────────────────────────────────────

RESULTS_DIR = 'results_price'
